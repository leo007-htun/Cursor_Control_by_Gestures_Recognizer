<div align="center">
    
[![PyPI version](https://img.shields.io/pypi/v/gTTS.svg)](https://pypi.org/project/gTTS/)
[![PyPI - Python Version](https://img.shields.io/badge/Python-%3E%3D%203.9-blue)](https://www.python.org/)
    
</div>


## Hand Landmark Detection with pre-trained model from Mediapipe

``mediapipe`` the MediaPipe Hands module from the MediaPipe library to detect and track hand landmarks in real-time from webcam feed. The specific model used is a pre-trained model provided by MediaPipe for hand tracking.

    model_complexity=0: 
    min_detection_confidence=0.5: 
    min_tracking_confidence=0.5: 
    
This first parameter controls the complexity of the hand tracking model. A value of 0 indicates the simplest model.This 2nd parameter sets the minimum confidence threshold for a hand detection to be considered valid. The 3rd parameter sets the minimum confidence threshold for hand landmarks to be considered during tracking.

## Installation

    $ git clone https://github.com/leo007-htun/GPT3_Automated_Assistant_with_wake_word.git
    

    $ pip install -r requirements.txt

replace ``YOUR_API_KEY`` with user's OpeanAI API key


## RUN
    $ source sr.sh to run in background



    
